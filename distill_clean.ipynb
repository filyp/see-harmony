{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from time import sleep\n",
    "\n",
    "from  pythagoras import PolyphonicPlayer\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "base_layout = dict(\n",
    "    template=\"plotly_dark\",\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peaks(amplitudes, height=400, distance=10):\n",
    "    amplitudes = np.abs(amplitudes)\n",
    "    peaks, peaks_prop = signal.find_peaks(amplitudes, height=height, distance=distance)\n",
    "    heights = amplitudes[peaks]\n",
    "    return peaks, heights\n",
    "\n",
    "\n",
    "def save_peaks_and_volumes(peaks, volumes, name):\n",
    "    npy_filename = os.path.join(\"chord_data\", f\"{name}.npy\")\n",
    "    with open(npy_filename, \"wb\") as f:\n",
    "        np.save(f, (peaks, volumes))\n",
    "        \n",
    "        \n",
    "def find_amplitudes(filename, lowest_frequency=30, octaves=7, bins_per_semitone=2):\n",
    "    # TODO add caching\n",
    "    rate, data = wav.read(filename)\n",
    "    data = data[:, 0] #+ data[:, 1]  # convert to mono\n",
    "\n",
    "    # note: resolution of the human ear is about 6 cents = 1/16 of a semitone\n",
    "    delta_f = 2 ** (1/12/bins_per_semitone) - 1\n",
    "    # based on https://dsp.stackexchange.com/questions/15574/morlet-wavelet-time-and-frequency-resolution\n",
    "    # but not sure about the calculation\n",
    "    omega = 1 / (np.sqrt(2) * delta_f)\n",
    "\n",
    "    frequencies = lowest_frequency * 2 ** np.arange(0, octaves, 1/12/bins_per_semitone)\n",
    "    widths = omega * rate / (2 * np.pi * frequencies)\n",
    "    wavelet_spectrum = signal.cwt(data, signal.morlet2, widths, w=omega)\n",
    "\n",
    "    wavelet_spectrum_abs = np.abs(wavelet_spectrum)\n",
    "    amplitudes = wavelet_spectrum_abs.mean(axis=1)\n",
    "    \n",
    "    return amplitudes, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/*.wav\")\n",
    "files = sorted(files, key=os.path.getmtime, reverse=True)\n",
    "\n",
    "fig = go.FigureWidget(layout=base_layout)\n",
    "fig.update_layout(\n",
    "    # xaxis_range=[0, len(total_means)],\n",
    "    # yaxis_range=[0, max(total_means)],\n",
    "    width=1500,\n",
    "    height=300,\n",
    ")\n",
    "fig.add_scattergl()\n",
    "\n",
    "\n",
    "player = PolyphonicPlayer(base_freq=1, max_voices=200)\n",
    "player.start()\n",
    "\n",
    "last_file = None\n",
    "\n",
    "@interact(file=files, height=(0, 100000), distance=(1, 30), bins_per_semitone=(1, 16), play=False)\n",
    "def update(file=None, height=0, distance=3, bins_per_semitone=2, play=False):\n",
    "    global peaks, volumes, last_file, amplitudes, frequencies\n",
    "    \n",
    "    if file is None:\n",
    "        return\n",
    "    \n",
    "    if last_file != file:\n",
    "        amplitudes, frequencies = find_amplitudes(file, bins_per_semitone=bins_per_semitone)\n",
    "        last_file = file\n",
    "        \n",
    "    peaks, volumes = get_peaks(amplitudes, height=height, distance=distance)\n",
    "    \n",
    "    player.ratios = frequencies[peaks]\n",
    "    if play:\n",
    "        player.volumes = volumes / np.sum(volumes)\n",
    "    else:\n",
    "        player.volumes = np.zeros(len(player.volumes))\n",
    "\n",
    "    shapes = list()\n",
    "    for peak, vol in zip(peaks, volumes):\n",
    "        shapes.append(\n",
    "            {\n",
    "                \"type\": \"line\",\n",
    "                \"line_color\": \"orange\",\n",
    "                \"x0\": peak,\n",
    "                \"y0\": 0,\n",
    "                \"x1\": peak,\n",
    "                \"y1\": vol,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with fig.batch_update():\n",
    "        fig.data[0].y = np.abs(amplitudes)\n",
    "        fig.layout.shapes = shapes\n",
    "        fig.update_layout(\n",
    "            xaxis_range=[0, len(amplitudes)],\n",
    "            yaxis_range=[0, max(amplitudes)],\n",
    "        )\n",
    "    print(len(peaks))\n",
    "\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.kill()\n",
    "player.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = os.path.split(filename)[1].split(\".\")[0]\n",
    "save_peaks_and_volumes(frequencies[peaks], volumes, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player.alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
